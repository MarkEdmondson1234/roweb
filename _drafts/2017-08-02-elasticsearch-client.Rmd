---
name: elasticsearch-client
layout: post_discourse
title: elastic - elasticsearch for R
authors:
  - name: Scott Chamberlain
categories:
  - technotes
topicid: xxx
tags:
- data
- datasets
- r
---

```{r echo=FALSE}
hook_output <- knitr::knit_hooks$get("output")
knitr::knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines) == 1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(if (abs(lines[1])>1) more else NULL,
           x[lines],
           if (length(x)>lines[abs(length(lines))]) more else NULL
    )
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE
)
```


**elastic** is an R client for [Elasticsearch][es]

`elastic` has been around since 2013, with the first commit in [November, 2013](https://github.com/ropensci/elastic/commit/f7b04589b2cb711a21223bb4f20b34bc9330ef8d).

> sidebar - 'elastic' was picked as a package named before the company now known as Elastic 
changed their name to Elastic. 

## What is Elasticsearch?

If you aren't familiar with Elasticsearch, it is a distributed, RESTful search and analytics engine. 
It's similar to Solr. It falls in the NoSQL bin of databases, holding data in JSON documents, instead
of rows and columns. Elasticsearch has a concept of __index__, similar to a database in SQL-land. 
You can hold many documents of similar type within a single index. There is powerful search 
capabilities, including lots of different types of queries that can be done separately 
or combined. And best of all it's super fast. 

## Other clients

The Elastic company maintains some official clients, including the Python client 
[elasticsearch-py](http://elasticsearch-py.readthedocs.io/en/master/), and it's higher
level DSL client [elasticsearch-dsl](https://elasticsearch-dsl.readthedocs.io/en/latest/).

I won't talk much about it, but we have slowly been working on an R equivalent of the 
Python DSL client, called [elasticdsl](https://github.com/ropensci/elasticdsl), for 
a human friendly way to compose Elasticsearch queries.


## Vignettes

Check out the [elastic introduction vignette](https://cran.rstudio.com/web/packages/elastic/vignettes/elastic_intro.html) 
and the [search vignette](https://cran.rstudio.com/web/packages/elastic/vignettes/search.html) to get started.

## Noteable features

* `elastic` has nearly complete coverage of the Elasticsearch HTTP API. If there's 
anything missing you need in this client, let us know!
* We fail well. This is important to us. We allow the user to choose simple errors 
to just give e.g., 404 HTTP error, or complex errors, including full stack trace 
from Elasticsearch in addition to the HTTP errror. We strive to fail well when 
users give the wrong type of input, etc. as well. Let us know if `elastic` is not
failing well!
* We strive to allow R centric ways of interacting with Elasticsearch. For example, 
in the function `docs_bulk`, our interface to the Elasticsearch [bulk API][bulk]
we make it easy to create documents in your Elasticsearch instance from R lists, 
data.frame's and from bulk format files on disk. 
* `elastic` works with most versions of Elasticsearch. We run the test suite on 11 
versions of Elasticsearch, from `v1.0.0` up to `v5.5.0`. We strive to fail well
with useful messages when there is a feature no longer available or one that is 
a new feature and not available in previous Elasticsearch versions.
* Search inputs are flexible: lists and JSON strings both work. 
* Arguably, a noteable feature is that this client has been around nearly 4 years,
so we've surfaced and squashed many bugs. 

## Setup

Install `elastic`


```{r eval=FALSE}
install.packages("elastic")
```

Or get the development version:

```{r eval=FALSE}
devtools::install_github("ropensci/elastic")
```


```{r}
library(elastic)
```

I'm running Elasticsearch version:

```{r}
ping()$version$number
```


## Examples


### Initialize a client

Using `connect()`

```{r}
elastic::connect()
```

By default, you connect to `localhost` and port `9200`. There's paramaters 
for setting transport schema, username, password, and base search path (e.g., 
`_search` or something else).

> See bottom of post about possible changes in connections.

### Get some data

Elasticsearch has a bulk load API to load data in fast. The format is pretty weird 
though. It's sort of JSON, but would pass no JSON linter. I include a few data 
sets in `elastic` so it's easy to get up and running, and so when you run examples 
in this package they'll actually run the same way (hopefully).

### Public Library of Science (PLOS) data

A dataset inluded in the `elastic` package is metadata for PLOS scholarly articles. 
Get the file path, then load:

```{r eval=FALSE}
plosdat <- system.file("examples", "plos_data.json", package = "elastic")
invisible(docs_bulk(plosdat))
```

### Search

The main search function is `Search()`. Running it without any inputs searches
across all indices - in this case only the `plos` index.

```{r eval=FALSE}
Search()
```

```{r echo=FALSE, output.lines=1:15}
Search("plos")
```

Search just the `plos` index and only return 1 result

```{r}
Search(index = "plos", size = 1)$hits$hits
```

Search the `plos` index, and the `article` document type, sort by title, and query for _antibody_, limit to 1 result. 

First, with Elasticsearch `v5` and greater, we need to set `fielddata = true` if we want to search on or sort on a text field.

```{r}
mapping_create("plos", "article", update_all_types = TRUE, body = '{
   "properties": {
     "title": { 
     "type":     "text",
     "fielddata": true
   }
 }
}')
Search(index = "plos", type = "article", sort = "title", q = "antibody", size = 1)$hits$hits
```

### Get documents

Get document with `id=1`

```{r}
docs_get(index = 'plos', type = 'article', id = 1)
```

Get certain fields

```{r}
docs_get(index = 'plos', type = 'article', id = 1, fields = 'id')
```


### Raw JSON data

You can optionally get back raw `json` from `Search()`, `docs_get()`, and `docs_mget()` setting parameter `raw=TRUE`.

For example, get raw JSON, then parse with `jsonlite`

```{r}
(out <- docs_mget(index = "plos", type = "article", id = 5:6, raw = TRUE))
jsonlite::fromJSON(out)
```

### Aggregation search

Here, we'll use another dataset that comes with the package on Shakespeare plays.

```{r}
gbifdat <- system.file("examples", "gbif_data.json", package = "elastic")
invisible(docs_bulk(gbifdat))
```

Define an aggregation query:

```{r}
aggs <- '{
    "aggs": {
        "latbuckets" : {
           "histogram" : {
               "field" : "decimalLatitude",
               "interval" : 5
           }
        }
    }
}'
```

Search the `gbif` index

```{r}
res <- Search(index = "gbif", body = aggs, size = 0)$aggregations$latbuckets$buckets
do.call("rbind.data.frame", res)
```

### Scrolling search - instead of paging

When you want all the documents, your best bet is likely to be [scrolling search](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html). 

Here's an example. First, let's we'll 

```{r}
res1 <- Search(index = 'shakespeare', scroll = "1m")
```

The scroll ID

```{r}
res1$`_scroll_id`
```

Here, use a while loop to get all results

```{r}
out1 <- list()
hits <- 1
while (hits != 0) {
  tmp1 <- scroll(scroll_id = res1$`_scroll_id`)
  hits <- length(tmp1$hits$hits)
  if (hits > 0) {
   out1 <- c(out1, tmp1$hits$hits) 
  }
}
```

Woohoo! Collected all `r length(out)` documents in very little time.

Now, get `_source` from each document:

```{r}
docs <- lapply(out1, "[[", "_source")
length(docs)
vapply(docs[1:10], "[[", "", "text_entry")
```


### Bulk documents

You've already seen the bulk docs API in action above. Above though, we were 
using `docs_bulk.character` - where the input is a character string that's a 
file path.

Here, I'll describe briefly how you can insert any data.frame as documents in your
Elasticsearch instance. We'll use the diamonds dataset from the ~54K row `ggplot2` 
package.

```{r echo=FALSE}
if (index_exists("diam")) index_delete("diam")
```

```{r}
library(ggplot2)
invisible(docs_bulk(diamonds, "diam"))
```

```{r}
Search("diam")$hits$total
```

That's pretty easy! This function is used a lot, particularly with data.frame's - so 
we get many questions/feedback on this so it will just keep getting better/faster.


## TO DO

### Connections

We're planning to roll out changes in how you connect to Elasticsearch from `elastic`. 
Right now, you can only connect to one Elasticsearch instance per R session - 
your details are set and then recalled internally in each function. We plan to change 
this to instantiate a client and then you either call functions on the client 
(e.g., using `R6`) or pass the client object onto functions.

Checkout [issue #87](https://github.com/ropensci/elastic/issues/87) to follow
progress or discuss.

### Move to using crul for http

`crul` is a relatively new R http client - and has async baked in - as well as mocking. 
Development should be easier with it as I can mock requests for test suites, and 
allow users to toggle async more easily.


## Call to action

We can use your help! Elasticsearch development moves pretty fast - we'd love this client to 
work with every single Elasticsearch version to the extent possible - and we'd love to 
squash every bug and solve every feature request fast. 

If you need to use Elasticsearch from R, please try out `elastic`!  

- Report bugs!
- File feature requests!
- Send PR's with bug fixes and features!


[es]: https://www.elastic.co/products/elasticsearch
[bulk]: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html
